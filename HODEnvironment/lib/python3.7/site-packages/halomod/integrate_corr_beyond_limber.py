"""
Created on 10/03/2015

@author: Steven

Module for routines and _frameworks that intelligently integrate the real-space
correlation function
"""
import numpy as np
from scipy.interpolate import InterpolatedUnivariateSpline as _spline
from scipy.integrate import simps, quad, dblquad
from .halo_model import HaloModel
from hmf import cached_quantity, parameter
from hmf import Cosmology as csm
import warnings
from scipy.special import legendre, spherical_jn
import hankel
from hankel import HankelTransform
import time
from . import tools


class ProjectedCF(HaloModel):
    def __init__(
        self,
        rp_min=0.01,
        rp_max=50.0,
        rp_num=30,
        rp_log=True,
        proj_limit=None,
        **kwargs
    ):
        # Set default rnum
        if "rnum" not in kwargs:
            kwargs["rnum"] = 5 * rp_num

        super(ProjectedCF, self).__init__(**kwargs)

        self.proj_limit = proj_limit
        self.rp_min = rp_min
        self.rp_max = rp_max
        self.rp_num = rp_num
        self.rp_log = rp_log

    @parameter("switch")
    def rp_min(self, val):
        return val

    @parameter("option")
    def rp_log(self, val):
        return bool(val)

    @parameter("res")
    def rp_max(self, val):
        return val

    @parameter("res")
    def rp_num(self, val):
        if val < 0:
            raise ValueError("rp_num must be > 0")
        return int(val)

    @parameter("switch")
    def proj_limit(self, val):
        return val

    @cached_quantity
    def rp(self):
        if isinstance(self.rp_min, (list, np.ndarray)):
            rp = np.array(self.rp_min)
        else:
            if self.rp_log:
                rp = np.logspace(
                    np.log10(self.rp_min), np.log10(self.rp_max), self.rp_num
                )
            else:
                rp = np.linspace(self.rp_min, self.rp_max, self.rp_num)

        return rp

    @cached_quantity
    def rlim(self):
        if self.proj_limit is None:
            rlim = max(80.0, 5 * self.rp.max())
        else:
            rlim = self.proj_limit
        return rlim
        
    @cached_quantity
    def corr_gg_0(self):
        return self.corr_gg

    @cached_quantity
    def corr_gg_2(self):
        t0 = time.time()
        ell = 2
        ht = HankelTransform(nu = ell + 0.5,
            N = 600,
            h = 0.005)
        k_hm = self.k_hm
        power_auto_tracer = self.power_auto_tracer
        power_auto_tracer_fnc = tools.ExtendedSpline(k_hm, power_auto_tracer, lower_func='power_law',
            upper_func='power_law', k=1)
        power_auto_tracer_interp = lambda k: self.power_1h_auto_tracer_fnc(k) * k**0.5 * np.sqrt(np.pi/2) * 1. /(2*np.pi**2.) * (1j)**ell
        xi_ell_1h = ht.transform(power_auto_tracer_interp, self.r, ret_err=False)/self.r**0.5
        power_auto_tracer = self.power_2h_auto_tracer
        #np.savetxt('k_hm.txt',k_hm)
        #np.savetxt('power_auto_tracer.txt',power_auto_tracer)
        power_2h_auto_tracer_fnc = tools.ExtendedSpline(k_hm, power_auto_tracer, lower_func='power_law',
            upper_func='power_law', k=1)
        power_auto_tracer_interp = lambda k: power_2h_auto_tracer_fnc(k) * k**0.5 * np.sqrt(np.pi/2) * 1. /(2*np.pi**2.) * (1j)**ell
        xi_ell_2h = ht.transform(power_auto_tracer_interp, self.r, ret_err=False)/self.r**0.5
        #np.savetxt('xi_2_hankel_1h.txt',np.real(xi_ell_1h))
        #np.savetxt('xi_2_hankel_2h.txt',np.real(xi_ell_2h))
        #np.savetxt('xi_2_hankel.txt',np.real(xi_ell_1h) + np.real(xi_ell_2h))
        #xi_ell = np.real(xi_ell_1h) + np.real(xi_ell_2h)
        cutoff_1h = 10.1
        xi_ell_1h_fixed = tools.ExtendedSpline(self.r[self.r < cutoff_1h], -1*np.real(xi_ell_1h)[self.r < cutoff_1h], lower_func='power_law',
            upper_func='power_law',k=1)
        #np.savetxt('corr_1h_auto_tracer.txt',self.corr_1h_auto_tracer)
        #np.savetxt('corr_2h_auto_tracer.txt',self.corr_2h_auto_tracer)
        #print('time for hankel',time.time()-t0)
        #np.savetxt('r.txt',self.r)
        #np.savetxt('self.corr_gg.txt',self.corr_gg)
        #k = np.logspace(-3,2,500000)
        #power_auto_tracer_interp = np.interp(k, k_hm, power_auto_tracer)
        #dk = np.gradient(k)
        #xi_ell = np.real((1j)**ell * 1./(2*np.pi**2.) * np.sum(dk * k**2 * power_auto_tracer_interp * spherical_jn(ell, k * self.r[:,np.newaxis]),axis=1))
        #np.savetxt('xi_2_direct.txt',xi_ell)
        #print('time for corr_gg_2',time.time()-t0)
        xi_ell = np.real(xi_ell_2h) - xi_ell_1h_fixed(self.r)
        #np.savetxt('xi_2_hankel_1h_fixed.txt',-1 * xi_ell_1h_fixed(self.r))
        #np.savetxt('xi_2_hankel.txt',xi_ell)
        return xi_ell

    @cached_quantity
    def corr_gg_4(self):
        t0 = time.time()
        ell = 4
        ht = HankelTransform(nu = ell + 0.5,
            N = 600,
            h = 0.005)
        k_hm = self.k_hm
        power_auto_tracer = self.power_auto_tracer
        power_auto_tracer_fnc = tools.ExtendedSpline(k_hm, power_auto_tracer, lower_func='power_law',
            upper_func='power_law', k=1)
        power_auto_tracer_interp = lambda k: self.power_1h_auto_tracer_fnc(k) * k**0.5 * np.sqrt(np.pi/2) * 1. /(2*np.pi**2.) * (1j)**ell
        xi_ell_1h = ht.transform(power_auto_tracer_interp, self.r, ret_err=False)/self.r**0.5
        power_auto_tracer = self.power_2h_auto_tracer
        #np.savetxt('k_hm.txt',k_hm)
        #np.savetxt('power_auto_tracer.txt',power_auto_tracer)
        power_2h_auto_tracer_fnc = tools.ExtendedSpline(k_hm, power_auto_tracer, lower_func='power_law',
            upper_func='power_law', k=1)
        power_auto_tracer_interp = lambda k: power_2h_auto_tracer_fnc(k) * k**0.5 * np.sqrt(np.pi/2) * 1. /(2*np.pi**2.) * (1j)**ell
        xi_ell_2h = ht.transform(power_auto_tracer_interp, self.r, ret_err=False)/self.r**0.5
        #np.savetxt('xi_4_hankel_1h.txt',np.real(xi_ell_1h))
        #np.savetxt('xi_4_hankel_2h.txt',np.real(xi_ell_2h))
        #np.savetxt('xi_4_hankel.txt',np.real(xi_ell_1h) + np.real(xi_ell_2h))
        #xi_ell = np.real(xi_ell_1h) + np.real(xi_ell_2h)
        cutoff_1h = 15.
        xi_ell_1h_fixed = tools.ExtendedSpline(self.r[self.r < cutoff_1h], np.real(xi_ell_1h)[self.r < cutoff_1h], lower_func='power_law',
            upper_func='power_law',k=1)
        #np.savetxt('corr_1h_auto_tracer.txt',self.corr_1h_auto_tracer)
        #np.savetxt('corr_2h_auto_tracer.txt',self.corr_2h_auto_tracer)
        #print('time for hankel',time.time()-t0)
        #np.savetxt('r.txt',self.r)
        #np.savetxt('self.corr_gg.txt',self.corr_gg)
        #k = np.logspace(-3,2,500000)
        #power_auto_tracer_interp = np.interp(k, k_hm, power_auto_tracer)
        #dk = np.gradient(k)
        #xi_ell = np.real((1j)**ell * 1./(2*np.pi**2.) * np.sum(dk * k**2 * power_auto_tracer_interp * spherical_jn(ell, k * self.r[:,np.newaxis]),axis=1))
        #np.savetxt('xi_2_direct.txt',xi_ell)
        #print('time for corr_gg_2',time.time()-t0)
        #np.savetxt('xi_4_hankel.txt',np.real(xi_ell_1h) + np.real(xi_ell_2h))
        xi_ell = np.real(xi_ell_2h) + xi_ell_1h_fixed(self.r)
        #np.savetxt('xi_4_hankel_1h_fixed.txt',xi_ell_1h_fixed(self.r))
        #np.savetxt('xi_4_hankel.txt',xi_ell)
        return xi_ell
        
    @cached_quantity
    def r(self):
        #return np.logspace(np.log10(self.rp.min()), np.log10(self.rlim), self.rnum)
        return np.logspace(-3,3,1000)
        
    @cached_quantity
    def projected_corr_gal(self):
        """
        Projected correlation function w(r_p).

        From Beutler 2011, eq 6.

        To integrate perform a substitution y = x - r_p.
        """
        return projected_corr_gal(self.r, self.corr_gg, self.rlim, self.rp)
        
    @cached_quantity
    def projected_corr_gal_rsd(self):
        """
        Projected correlation function w(r_p).

        From Beutler 2011, eq 6.

        To integrate perform a substitution y = x - r_p.
        """
        Om0 = self.transfer.cosmo.Om0
        Omz = (Om0* (1 + (self.z))**3.)/((Om0) * (1 + (self.z))**3. + (1 -Om0))
        f = Omz**0.55
        return projected_corr_gal_rsd(self.r, self.corr_gg_0, self.corr_gg_2, self.corr_gg_4, self.rlim, f/self.bias_effective_tracer, self.rp)


def projected_corr_gal(
    r: np.ndarray, xir: np.ndarray, rlim: np.ndarray, rp_out: [None, np.ndarray] = None
):
    """
    Projected correlation function w(r_p).

    From Beutler 2011, eq 6.

    To integrate, we perform a substitution y = x - r_p.

    Parameters
    ----------
    r : float array
        Array of scales for the 3D correlation function, in [Mpc/h]
    xir : float array
        3D correlation function Array of xi(r), unitless.
    rlim :
    """
    if rp_out is None:
        rp_out = r

    xir[np.isnan(xir)] = 0.0 # added to deal with xir = nan at large R


    lnr = np.log(r)
    lnxi = np.log(xir)

    p = np.zeros_like(rp_out)
    fit = _spline(r, xir, k=3)  # [self.corr_gal > 0] maybe?
    f_peak = 0.01
    a = 0

    for i, rp in enumerate(rp_out):
        if a != 1.3 and i < len(r) - 1:
            # Get log slope at rp
            ydiff = (lnxi[i + 1] - lnxi[i]) / (lnr[i + 1] - lnr[i])
            # if the slope is flatter than 1.3, it will converge faster, but to make
            # sure, we cut at 1.3
            a = max(1.3, -ydiff)
            theta = _get_theta(a)

        min_y = theta * f_peak ** 2 * rp

        # Get the upper limit for this rp
        #ylim = rlim - rp
        ylim = (rlim **2 + rp**2.)**0.5 - rp

        # Set the y vector for this rp
        y = np.logspace(np.log(min_y), np.log(ylim), 1000, base=np.e)

        # Integrate
        pi = (r**2 - rp**2.)**0.5
        mu = pi/r
        integ_corr = fit(y + rp)
        integrand = (y + rp) * integ_corr / np.sqrt((y + 2 * rp) * y)
        p[i] = simps(integrand, y) * 2

    return p
    
    
def projected_corr_gal_rsd(
    r: np.ndarray, xir_0: np.ndarray, xir_2: np.ndarray, xir_4: np.ndarray,
    rlim: np.ndarray, beta: np.float, rp_out: [None, np.ndarray] = None
):
    """
    Projected correlation function w(r_p), with RSD added.

    From Beutler 2011, eq 6.

    To integrate, we perform a substitution y = x - r_p.

    Parameters
    ----------
    r : float array
        Array of scales for the 3D correlation function, in [Mpc/h]
    xir : float array
        3D correlation function Array of xi(r), unitless.
    rlim :
    """
    if rp_out is None:
        rp_out = r

    xir_0[np.isnan(xir_0)] = 0.0 # added to deal with xir = nan at large R
    xir_2[np.isnan(xir_2)] = 0.0 # added to deal with xir = nan at large R
    xir_4[np.isnan(xir_4)] = 0.0 # added to deal with xir = nan at large R

    lnr = np.log(r)
    lnxi = np.log(xir_0)

    p = np.zeros_like(rp_out)
    fit_0 = _spline(r, xir_0, k=3)  # [self.corr_gal > 0] maybe?
    fit_2 = _spline(r, xir_2, k=3)  # [self.corr_gal > 0] maybe?
    fit_4 = _spline(r, xir_4, k=3)  # [self.corr_gal > 0] maybe?
    
    alpha_0 = 1 + (2./3.) * beta + (1./5.) * beta**2.
    alpha_2 = (4./3.) * beta + (4./7.) * beta**2.
    alpha_4 = (8./35.) * beta**2.
    
    f_peak = 0.01
    a = 0

    for i, rp in enumerate(rp_out):
        if a != 1.3 and i < len(r) - 1:
            # Get log slope at rp
            ydiff = (lnxi[i + 1] - lnxi[i]) / (lnr[i + 1] - lnr[i])
            # if the slope is flatter than 1.3, it will converge faster, but to make
            # sure, we cut at 1.3
            a = max(1.3, -ydiff)
            theta = _get_theta(a)

        min_y = theta * f_peak ** 2 * rp

        # Get the upper limit for this rp
        #ylim = rlim - rp
        ylim = (rlim **2 + rp**2.)**0.5 - rp

        # Set the y vector for this rp
        y = np.logspace(np.log(min_y), np.log(ylim), 1000, base=np.e)

        # Integrate
        pi = np.sqrt((y + 2 * rp) * y)
        mu = pi/(y + rp)
        integ_corr = (fit_0(y + rp) * legendre(0)(mu) * alpha_0
         + fit_2(y + rp) * legendre(2)(mu) * alpha_2
         + fit_4(y + rp) * legendre(4)(mu) * alpha_4)
        #integ_corr = fit(y + rp)
        integrand = (y + rp) * integ_corr / pi
        p[i] = simps(integrand, y) * 2

    return p

def _get_theta(a):
    theta = (
        2 ** (1 + 2 * a)
        * (
            7
            - 2 * a ** 3
            + 3 * np.sqrt(5 - 8 * a + 4 * a ** 2)
            + a ** 2 * (9 + np.sqrt(5 - 8 * a + 4 * a ** 2))
            - a * (13 + 3 * np.sqrt(5 - 8 * a + 4 * a ** 2))
        )
        * ((1 + np.sqrt(5 - 8 * a + 4 * a ** 2)) / (a - 1)) ** (-2 * a)
    )
    theta /= (a - 1) ** 2 * (-1 + 2 * a + np.sqrt(5 - 8 * a + 4 * a ** 2))
    return theta


def flat_z_dist(zmin, zmax):
    def ret(z):
        z = np.atleast_1d(z)
        return np.where(np.logical_and(z >= zmin, z <= zmax), 1.0 / (zmax - zmin), 0)

    return ret


def dxdz(z, cosmo=csm().cosmo):
    """Derivative of comoving distance with redshift [Mpc/h]."""
    dh = cosmo.hubble_distance * cosmo.h
    return dh.value / cosmo.efunc(z)


class AngularCF(HaloModel):
    """
    Framework extension to angular correlation functions.

    Parameters
    ----------
    p1 : callable, optional
        The redshift distribution of the sample. This needs not
        be normalised to 1, as this will occur internally. May be
        either a function of radial distance [Mpc/h] or redshift.
        If a function of radial distance, `p_of_z` must be set to
        False. Default is a flat distribution in redshift.
    p2 : callable, optional
        See `p1`. This can optionally be a different function against
        which to cross-correlate. By default is equivalent to `p1`.
    theta_min, theta_max : float, optional
        min,max angular separations [Rad]
    theta_num : int, optional
        Number of steps in angular separation
    theta_log : bool, optional
        Whether to use logspace for theta values
    zmin, zmax : float, optional
        The redshift limits of the sample distribution. Note that
        this is in redshit, regardless of the value of `p_of_z`.
    znum : int, optional
        Number of steps in redshift grid.
    logu_min, logu_max : float, optional
        min,max of the log10 of radial separation grid [Mpc/h]. Must be large
        enough to let the integral over the 3D correlation function to converge.
    unum : int, optional
        Number of steps in the u grid.
    check_p_norm : bool, optional
        If False, cancels checking the normalisation of `p1` and `p2`.
    p_of_z : bool, optional
        Whether `p1` and `p2` are functions of redshift.
    kwargs : unpacked-dict
        Any keyword arguments passed down to :class:`halomod.HaloModel`.
    """

    def __init__(
        self,
        p1=None,
        p2=None,
        theta_min=1e-3 * np.pi / 180.0,
        theta_max=np.pi / 180.0,
        theta_num=30,
        theta_log=True,
        zmin=0.2,
        zmax=0.4,
        znum=100,
        logu_min=-4,
        logu_max=2.3,
        unum=100,
        check_p_norm=True,
        p_of_z=True,
        **kwargs
    ):
        super(AngularCF, self).__init__(**kwargs)

        if self.z < zmin or self.z > zmax:
            warnings.warn(
                "Your specified redshift (z=%s) is not within your selection function, z=(%s,%s)"
                % (self.z, zmin, zmax)
            )

        if p1 is None:
            p1 = flat_z_dist(zmin, zmax)

        self.p1 = p1
        self.p2 = p2
        self.zmin = zmin
        self.zmax = zmax
        self.znum = znum
        self.logu_min = logu_min
        self.logu_max = logu_max
        self.unum = unum
        self.check_p_norm = check_p_norm
        self.p_of_z = p_of_z

        self.theta_min = theta_min
        self.theta_max = theta_max
        self.theta_num = theta_num
        self.theta_log = theta_log

    @parameter("param")
    def p1(self, val):
        return val

    @parameter("param")
    def p2(self, val):
        return val

    @parameter("model")
    def p_of_z(self, val):
        return val

    @parameter("res")
    def theta_min(self, val):
        if val < 0:
            raise ValueError("theta_min must be > 0")
        return val

    @parameter("res")
    def theta_max(self, val):
        if val > 180.0:
            raise ValueError("theta_max must be < 180.0")
        return val

    @parameter("res")
    def theta_num(self, val):
        return val

    @parameter("res")
    def theta_log(self, val):
        return val

    @parameter("param")
    def zmin(self, val):
        return val

    @parameter("param")
    def zmax(self, val):
        return val

    @parameter("res")
    def znum(self, val):
        return val

    @parameter("res")
    def logu_min(self, val):
        return val

    @parameter("res")
    def logu_max(self, val):
        return val

    @parameter("res")
    def unum(self, val):
        return val

    @parameter("option")
    def check_p_norm(self, val):
        return val

    @cached_quantity
    def zvec(self):
        """
        Redshift distribution grid.
        """
        return np.linspace(self.zmin, self.zmax, self.znum)

    @cached_quantity
    def uvec(self):
        """Radial separation grid [Mpc/h]."""
        return np.logspace(self.logu_min, self.logu_max, self.unum)

    @cached_quantity
    def xvec(self):
        """Radial distance grid (corresponds to zvec) [Mpc/h]."""
        return self.cosmo.comoving_distance(self.zvec).value

    @cached_quantity
    def theta(self):
        """Angular separations, [Rad]."""
        if self.theta_min > self.theta_max:
            raise ValueError("theta_min must be less than theta_max")

        if self.theta_log:
            return np.logspace(
                np.log10(self.theta_min), np.log10(self.theta_max), self.theta_num
            )
        else:
            return np.linspace(self.theta_min, self.theta_max, self.theta_num)

    @cached_quantity
    def corr_gg_0(self):
        return self.corr_gg

    @cached_quantity
    def corr_gg_2(self):
        t0 = time.time()
        ell = 2
        ht = HankelTransform(nu = ell + 0.5,
            N = 600,
            h = 0.005)
        k_hm = self.k_hm
        power_auto_tracer = self.power_auto_tracer
        power_auto_tracer_fnc = tools.ExtendedSpline(k_hm, power_auto_tracer, lower_func='power_law',
            upper_func='power_law', k=1)
        power_auto_tracer_interp = lambda k: self.power_1h_auto_tracer_fnc(k) * k**0.5 * np.sqrt(np.pi/2) * 1. /(2*np.pi**2.) * (1j)**ell
        xi_ell_1h = ht.transform(power_auto_tracer_interp, self.r, ret_err=False)/self.r**0.5
        power_auto_tracer = self.power_2h_auto_tracer
        power_2h_auto_tracer_fnc = tools.ExtendedSpline(k_hm, power_auto_tracer, lower_func='power_law',
            upper_func='power_law', k=1)
        power_auto_tracer_interp = lambda k: power_2h_auto_tracer_fnc(k) * k**0.5 * np.sqrt(np.pi/2) * 1. /(2*np.pi**2.) * (1j)**ell
        xi_ell_2h = ht.transform(power_auto_tracer_interp, self.r, ret_err=False)/self.r**0.5
        cutoff_1h = 10.1
        xi_ell_1h_fixed = tools.ExtendedSpline(self.r[self.r < cutoff_1h], -1*np.real(xi_ell_1h)[self.r < cutoff_1h], lower_func='power_law',
            upper_func='power_law',k=1)
        #print('time for hankel',time.time()-t0)
        xi_ell = np.real(xi_ell_2h) - xi_ell_1h_fixed(self.r)
        return xi_ell

    @cached_quantity
    def corr_gg_4(self):
        t0 = time.time()
        ell = 4
        ht = HankelTransform(nu = ell + 0.5,
            N = 600,
            h = 0.005)
        k_hm = self.k_hm
        power_auto_tracer = self.power_auto_tracer
        power_auto_tracer_fnc = tools.ExtendedSpline(k_hm, power_auto_tracer, lower_func='power_law',
            upper_func='power_law', k=1)
        power_auto_tracer_interp = lambda k: self.power_1h_auto_tracer_fnc(k) * k**0.5 * np.sqrt(np.pi/2) * 1. /(2*np.pi**2.) * (1j)**ell
        xi_ell_1h = ht.transform(power_auto_tracer_interp, self.r, ret_err=False)/self.r**0.5
        power_auto_tracer = self.power_2h_auto_tracer
        power_2h_auto_tracer_fnc = tools.ExtendedSpline(k_hm, power_auto_tracer, lower_func='power_law',
            upper_func='power_law', k=1)
        power_auto_tracer_interp = lambda k: power_2h_auto_tracer_fnc(k) * k**0.5 * np.sqrt(np.pi/2) * 1. /(2*np.pi**2.) * (1j)**ell
        xi_ell_2h = ht.transform(power_auto_tracer_interp, self.r, ret_err=False)/self.r**0.5
        cutoff_1h = 15.
        xi_ell_1h_fixed = tools.ExtendedSpline(self.r[self.r < cutoff_1h], np.real(xi_ell_1h)[self.r < cutoff_1h], lower_func='power_law',
            upper_func='power_law',k=1)
        #print('time for hankel',time.time()-t0)
        xi_ell = np.real(xi_ell_2h) + xi_ell_1h_fixed(self.r)
        return xi_ell

    @cached_quantity
    def r(self):
        """Physical separation grid [Mpc/h]."""
        rmin = np.sqrt(
            (10 ** self.logu_min) ** 2 + self.theta.min() ** 2 * self.xvec.min() ** 2
        )
        rmax = np.sqrt(
            (10 ** self.logu_max) ** 2 + self.theta.max() ** 2 * self.xvec.max() ** 2
        )
        return np.logspace(np.log10(rmin), np.log10(rmax), self.rnum)

    @cached_quantity
    def angular_corr_gal(self):
        """The angular correlation function w(theta).

        From Blake+08, Eq. 33
        """

        #print('got to angular_corr_gal in AngularCF')
        def xi(r):
            s = _spline(self.r, self.corr_gg, ext='zeros')
            return s(r)
        r=np.linspace(0.5,10,1000)
        #print('xi',xi(r))

        return angular_corr_gal(
            self.theta,
            xi,
            self.p1,
            self.zmin,
            self.zmax,
            self.logu_min,
            self.logu_max,
            znum=self.znum,
            unum=self.unum,
            p2=self.p2,
            check_p_norm=self.check_p_norm,
            cosmo=self.cosmo,
            p_of_z=self.p_of_z,
        )
    @cached_quantity
    def angular_corr_gal_rsd(self):
        Om0 = self.transfer.cosmo.Om0
        Omz = (Om0* (1 + (self.z))**3.)/((Om0) * (1 + (self.z))**3. + (1 -Om0))
        f = Omz**0.55

        return angular_corr_gal_rsd(
            self.theta,
            self.r,
            self.corr_gg_0,
            self.corr_gg_2,
            self.corr_gg_4,
            f/self.bias_effective_tracer,
            self.p1,
            self.zmin,
            self.zmax,
            self.logu_min,
            self.logu_max,
            znum=self.znum,
            unum=self.unum,
            p2=self.p2,
            check_p_norm=self.check_p_norm,
            cosmo=self.cosmo,
            p_of_z=self.p_of_z
        )

    @cached_quantity
    def angular_corr_matter(self):
        """
        The angular correlation function w(theta).

        From Blake+08, Eq. 33
        """

        def xi(r):
            s = _spline(self.r, self.corr_mm)
            return s(r)

        return angular_corr_gal(
            self.theta,
            xi,
            self.p1,
            self.zmin,
            self.zmax,
            self.logu_min,
            self.logu_max,
            znum=self.znum,
            unum=self.unum,
            p2=self.p2,
            check_p_norm=self.check_p_norm,
            cosmo=self.cosmo,
            p_of_z=self.p_of_z,
        )


def _check_p(p, z):
    if hasattr(p, "integral"):
        integ = p.integral(z.min(), z.max())
    else:
        integ = simps(p(z), z)
    if not np.isclose(integ, 1.0, rtol=0.01):
        print(
            "WARNING: Filter function p(x) did not integrate to 1 (%s). Tentatively re-normalising."
            % integ
        )
        return lambda z: p(z) / integ
    else:
        return p


def angular_corr_gal(
    theta,
    xi,
    p1,
    zmin,
    zmax,
    logu_min,
    logu_max,
    znum=100,
    unum=100,
    p2=None,
    check_p_norm=True,
    cosmo=None,
    p_of_z=True,
    **xi_kw
):
    """
    Calculate the angular correlation function w(theta).

    From Blake+08, Eq. 33. That is, this uses the Limber approximation.
    This does not hold either for wide angles, or thin radial distributions.

    Parameters
    ----------
    theta : array_like
        Angles at which to calculate the angular correlation. In radians.
    xi : callable
        A function of one variable: r [Mpc/h], which returns
        the 3D correlation function at the scale r.
    p1: callable
        The redshift distribution of sources. Should integrate to 1 between
        `logz_min` and `logz_max`. A callable function of a single variable, z.
    zmin, zmax : float
        The redshift limits of the sample distribution. Note that
        this is in redshift, regardless of the value of `p_of_z`.
    logu_min, logu_max : float
        min,max of the log10 of radial separation grid [Mpc/h]. Must be large
        enough to let the integral over the 3D correlation function to converge.
    znum : int, optional
        Number of steps in redshift grid.
    unum : int, optional
        Number of steps in the u grid.
    p2 : callable, optional
        The same as `p1`, but for a second, cross-correlating dataset. If not
        provided, defaults to `p1` (i.e. auto-correlation).
    check_p_norm : bool, optional
        If False, cancels checking the normalisation of `p1` and `p2`.
    p_of_z : bool, optional
        Whether `p1` and `p2` are functions of redshift.
    cosmo : `hmf.cosmo.Cosmology` instance, optional
        A cosmology, used to generate comoving distance from redshift. Default
        is the default cosmology of the `hmf` package.
    xi_kw : unpacked-dict
        Any arguments to `xi` other than r,z.

    Returns
    -------
    wtheta : array_like
        The angular correlation function corresponding to `theta`.
    """
    if cosmo is None:
        cosmo = csm().cosmo

    # Arrays
    u = np.logspace(logu_min, logu_max, unum)
    
    #znum = 100

    if p_of_z:
        z = np.linspace(zmin, zmax, znum)
        x = (cosmo.comoving_distance(z) * cosmo.h).value
    else:
        xmin = (cosmo.comoving_distance(zmin) * cosmo.h).value
        xmax = (cosmo.comoving_distance(zmax) * cosmo.h).value
        rbar = np.linspace(xmin, xmax, znum)
        #print('rbar',rbar)
        #print(5/0)
        #rbar = np.logspace(np.log10(xmin), np.log10(xmax), znum)
        x = np.linspace(xmin, xmax, znum)
        z_for_test = np.linspace(zmin, zmax, 100 * znum)
        rbar_for_test = (cosmo.comoving_distance(z_for_test) * cosmo.h).value
        z_of_r = _spline(rbar_for_test, z_for_test)
        z_of_rbar = z_of_r(rbar)
        
    if check_p_norm:
        p1 = _check_p(p1, z if p_of_z else x)

    if p2 is None:
        p2 = p1
    elif check_p_norm:
        p2 = _check_p(p2, z if p_of_z else x)
        
    #print('p1',p1(rbar))
    #print('p2',p2(rbar))
    


        
    
    N_bigR = 100000
    for j,theta_ind in enumerate(theta):
        integrand_all = 0
        drbar = np.gradient(rbar)
        #f = open('/home/jptlawre/projects/rrg-wperciva/jptlawre/test/%i_integrand_all.txt' % j,'w')
        for i,rbar_ind in enumerate(rbar):
            #print(i, rbar_ind)
            t0 = time.time()
            bigR_min = rbar_ind * np.sqrt( 2 * (1  - np.cos(theta_ind)))
            bigR_max = 2 * rbar_ind
            #print('limits',time.time()-t0)
            #bigR_max = 150.
            #bigR = np.linspace(bigR_min, bigR_max, N_bigR)
            bigR = np.logspace(np.log10(bigR_min),np.log10(bigR_max), N_bigR)
            Delta = 1./np.sqrt(2.) * np.sqrt(bigR ** 2 - 2 * rbar_ind ** 2 * (1 - np.cos(theta_ind)))/np.sqrt( 1 + np.cos(theta_ind))
            #print('Delta',time.time()-t0)
            Delta[0] = 0
            Q = p1(rbar_ind - Delta) * p2(rbar_ind + Delta) + p1(rbar_ind + Delta) * p2(rbar_ind - Delta)
            #print('Q',time.time()-t0)
            dbigR = np.gradient(bigR)
            ratio = bigR/Delta
            ratio[0] = 0
            integrand = dbigR * Q * xi(bigR) * ratio # xi can be a function of z as well, but it is very slow!
            #print('integrand',time.time()-t0)
            #print('integrand',integrand)
            #print('bigR',bigR)
            integral = np.sum(integrand)
            integrand_all += integral * drbar[i]
            #print('integrand_all',integrand_all)
            #print('integrand all',time.time()-t0)
            #f.write('%10.5e\n' % (integral * drbar[i]))
        w = integrand_all/(1 + np.cos(theta_ind))
        #f.close()
        #print('theta_ind',theta_ind)
        print('w',w)
        #break
        
        

    p_integ = p1(z) * p2(z) / dxdz(z, cosmo) if p_of_z else p1(x) * p2(x)
    R = np.sqrt(np.add.outer(np.outer(theta ** 2, x ** 2), u ** 2)).flatten()
    integrand = np.einsum(
        "kij,i->kij", xi(R, **xi_kw).reshape((len(theta), len(x), len(u))), p_integ
    )
    
    testR = np.linspace(0.1, 160, 1000)
    testxi = xi(testR)
    #np.savetxt('testxi_for_no-rsd.txt',np.array([testR, testxi]).T)



    out = 2 * simps(simps(integrand, u), x)
    print('out',out)
    return out


def angular_corr_gal_rsd(
    theta: np.ndarray, r: np.ndarray, xir_0: np.ndarray, xir_2: np.ndarray, xir_4: np.ndarray,
    beta: np.ndarray, p1, zmin, zmax, logu_min, logu_max, znum=100, unum=100,
    p2=None, check_p_norm=True, cosmo=None, p_of_z=True, beta2=0, **xi_kw
):
    t0 = time.time()

    if cosmo is None:
        cosmo = csm().cosmo

    xir_0[np.isnan(xir_0)] = 0.0 # added to deal with xir = nan at large R
    xir_2[np.isnan(xir_2)] = 0.0 # added to deal with xir = nan at large R
    xir_4[np.isnan(xir_4)] = 0.0 # added to deal with xir = nan at large R
    

    fit_0 = _spline(r, xir_0, k=3, ext='zeros')  # [self.corr_gal > 0] maybe?
    fit_2 = _spline(r, xir_2, k=3, ext='zeros')  # [self.corr_gal > 0] maybe?
    fit_4 = _spline(r, xir_4, k=3, ext='zeros')  # [self.corr_gal > 0] maybe?
    
    if not beta2:
        beta2 = beta
        
    alpha_0 = 1 + (1./3.) * (beta + beta2) + (1./5.) * (beta * beta2)
    alpha_2 = (2./3.) * (beta + beta2) + (4./7.) * (beta * beta2)
    alpha_4 = (8./35.) * (beta * beta2)

    #alpha_0 = 1 + (2./3.) * beta + (1./5.) * beta**2.
    #alpha_2 = (4./3.) * beta + (4./7.) * beta**2.
    #alpha_4 = (8./35.) * beta**2.

    xi_rsd = lambda r, mu: (fit_0(r) * legendre(0)(mu) * alpha_0
                           + fit_2(r) * legendre(2)(mu) * alpha_2
                           + fit_4(r) * legendre(4)(mu) * alpha_4)
    
    
    

    # Arrays
    u = np.logspace(logu_min, logu_max, unum)
        
    if p_of_z:
        z = np.linspace(zmin, zmax, znum)
        x = (cosmo.comoving_distance(z) * cosmo.h).value
    else:
        xmin = (cosmo.comoving_distance(zmin) * cosmo.h).value
        xmax = (cosmo.comoving_distance(zmax) * cosmo.h).value
        rbar = np.linspace(xmin, xmax, znum)
        x = np.linspace(xmin, xmax, znum)
        z_for_test = np.linspace(zmin, zmax, 100 * znum)
        rbar_for_test = (cosmo.comoving_distance(z_for_test) * cosmo.h).value
        z_of_r = _spline(rbar_for_test, z_for_test)
        z_of_rbar = z_of_r(rbar)

    if check_p_norm:
        p1 = _check_p(p1, z if p_of_z else x)

    if p2 is None:
        p2 = p1
        auto = True
    else:
        auto = False
    if check_p_norm:
        p2 = _check_p(p2, z if p_of_z else x)
        
    
    drbar = np.gradient(rbar)
    w = np.zeros(len(theta))
    print(time.time()-t0,'got to loop')
    for j,theta_ind in enumerate(theta):
        integrand_all = 0
        
        #t0 = time.time()
        if auto == False:
            if theta_ind < 0.00017:
                N_bigR = 200000//8
            elif theta_ind < 0.00102:
                N_bigR = 100000//2
            else:
                N_bigR = 40000
        else:
            if theta_ind < 0.00102:
                N_bigR = 200000//4
            elif theta_ind < 0.00162:
                N_bigR = 100000//2
            else:
                N_bigR = 40000//2
        bigR_min = rbar * np.sqrt( 2 * (1  - np.cos(theta_ind)))
        bigR_max = 2 * rbar
        
        new_Rmax1 = np.sqrt(2 * (1 + np.cos(theta_ind)) * (rbar - xmin)**2 + 2 * rbar**2. * (1 - np.cos(theta_ind)))
        new_Rmax2 = np.sqrt(2 * (1 + np.cos(theta_ind)) * (xmax - rbar)**2 + 2 * rbar**2. * (1 - np.cos(theta_ind)))
        new_Rmax = np.nanmin((new_Rmax1, new_Rmax2),axis=0)
        
        bigR = 10**(np.logspace(np.log10(np.log10(bigR_min)+1.5), np.log10(np.log10(new_Rmax)+1.5), N_bigR))/10**1.5
        Delta = 1./np.sqrt(2.) * np.sqrt(bigR ** 2 - 2 * rbar ** 2 * (1 - np.cos(theta_ind)))/np.sqrt( 1 + np.cos(theta_ind))
        Delta[0,:] = 0
        Delta[np.isnan(Delta)] = 0
        
        if auto:
            Q = 2 * p1(rbar[np.newaxis,:] - Delta) * p2(rbar[np.newaxis,:] + Delta)
        else:
            Q = p1(rbar[np.newaxis,:] - Delta) * p2(rbar[np.newaxis,:] + Delta) + p1(rbar[np.newaxis,:] + Delta) * p2(rbar[np.newaxis,:] - Delta)
        Q[0,:] = 0
        Q[np.isnan(Q)] = 0

        dbigR = np.gradient(bigR, axis=0)
        ratio = bigR/Delta
        ratio[0,:] = 0
        ratio[np.isnan(ratio)] = 0
        ratio[np.isinf(ratio)] = 0

        delta_r = (2 * (bigR **2 - 2 * rbar **2 * (1 - np.cos(theta_ind)))/(1 + np.cos(theta_ind))) ** 0.5
        delta_r[0,:] = 0
        delta_r[np.isnan(delta_r)] = 0
        r1 = rbar - delta_r
        phi = np.arcsin(r1 * np.sin(theta_ind)/bigR)
        phi[0,:] = 0
        phi[np.isnan(phi)] = 0
        phi[phi < 0] = phi[phi < 0] + np.pi
        mu = -np.cos(np.pi - theta_ind/2. - phi)

        integrand = Q * xi_rsd(bigR, mu) * ratio
        integrand_all = np.zeros(len(rbar))
        for i in range(len(rbar)):
            simps_res = simps(integrand[:,i] , bigR[:,i], axis=0)
            if np.isnan(simps_res):
                simps_res = 0
            integrand_all[i] = simps_res
        integrand_all = simps(integrand_all, rbar)
        
        w[j] = integrand_all/(1 + np.cos(theta_ind))
        print('loop j',j,time.time()-t0)
    print('done with angular corr gal rsd',time.time()-t0)
    return w
